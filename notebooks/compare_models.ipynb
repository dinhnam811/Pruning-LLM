{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Original vs Pruned Model\n",
    "This notebook compares the original Qwen2.5-Coder-3B-Instruct with your pruned model.\n",
    "\n",
    "We will test both models on 20 Java coding problems and compare:\n",
    "- **Speed**: How fast each model generates code\n",
    "- **Accuracy**: How many problems each model solves correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/prune_llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1\n",
      "CUDA available: False\n",
      "Transformers version: 4.57.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "# Check for transformers version\n",
    "import transformers\n",
    "print(f\"Transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Test Problems\n",
    "We'll use the first 20 problems from the Java benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 test problems\n"
     ]
    }
   ],
   "source": [
    "# Simple test problems (first 20)\n",
    "benchmark = [\n",
    "  {\"id\": \"java_001_is_prime\", \"prompt\": \"Write a Java method isPrime that returns true if n is a prime number, otherwise false.\", \"signature\": \"public static boolean isPrime(int n)\", \"tests\": [{\"input\": \"2\", \"expected\": \"true\"}, {\"input\": \"4\", \"expected\": \"false\"}, {\"input\": \"17\", \"expected\": \"true\"}]},\n",
    "  {\"id\": \"java_002_reverse_string\", \"prompt\": \"Write a Java method reverseString that returns the reversed version of the input string.\", \"signature\": \"public static String reverseString(String s)\", \"tests\": [{\"input\": \"\\\"abc\\\"\", \"expected\": \"\\\"cba\\\"\"}, {\"input\": \"\\\"hello\\\"\", \"expected\": \"\\\"olleh\\\"\"}]},\n",
    "  {\"id\": \"java_003_sum_array\", \"prompt\": \"Write a Java method sumArray that returns the sum of all elements in the given integer array.\", \"signature\": \"public static int sumArray(int[] arr)\", \"tests\": [{\"input\": \"new int[]{1, 2, 3}\", \"expected\": \"6\"}, {\"input\": \"new int[]{0, 0, 0}\", \"expected\": \"0\"}]},\n",
    "  {\"id\": \"java_004_factorial\", \"prompt\": \"Write a Java method factorial that returns n! (n factorial). Assume n is non-negative.\", \"signature\": \"public static long factorial(int n)\", \"tests\": [{\"input\": \"0\", \"expected\": \"1\"}, {\"input\": \"5\", \"expected\": \"120\"}]},\n",
    "  {\"id\": \"java_005_max_in_array\", \"prompt\": \"Write a Java method maxInArray that returns the maximum value in the given integer array.\", \"signature\": \"public static int maxInArray(int[] arr)\", \"tests\": [{\"input\": \"new int[]{1, 2, 3}\", \"expected\": \"3\"}, {\"input\": \"new int[]{-1, -5, -3}\", \"expected\": \"-1\"}]},\n",
    "  {\"id\": \"java_006_min_in_array\", \"prompt\": \"Write a Java method minInArray that returns the minimum value in the given integer array.\", \"signature\": \"public static int minInArray(int[] arr)\", \"tests\": [{\"input\": \"new int[]{1, 2, 3}\", \"expected\": \"1\"}, {\"input\": \"new int[]{-1, -5, -3}\", \"expected\": \"-5\"}]},\n",
    "  {\"id\": \"java_007_is_palindrome\", \"prompt\": \"Write a Java method isPalindrome that returns true if the given string is a palindrome.\", \"signature\": \"public static boolean isPalindrome(String s)\", \"tests\": [{\"input\": \"\\\"racecar\\\"\", \"expected\": \"true\"}, {\"input\": \"\\\"abc\\\"\", \"expected\": \"false\"}]},\n",
    "  {\"id\": \"java_008_count_vowels\", \"prompt\": \"Write a Java method countVowels that returns the number of vowels in the given string.\", \"signature\": \"public static int countVowels(String s)\", \"tests\": [{\"input\": \"\\\"hello\\\"\", \"expected\": \"2\"}, {\"input\": \"\\\"AEIOU\\\"\", \"expected\": \"5\"}]},\n",
    "  {\"id\": \"java_009_fibonacci\", \"prompt\": \"Write a Java method fibonacci that returns the n-th Fibonacci number.\", \"signature\": \"public static int fibonacci(int n)\", \"tests\": [{\"input\": \"0\", \"expected\": \"0\"}, {\"input\": \"5\", \"expected\": \"5\"}]},\n",
    "  {\"id\": \"java_010_find_index\", \"prompt\": \"Write a Java method findIndex that returns the index of target in the array, or -1 if not found.\", \"signature\": \"public static int findIndex(int[] arr, int target)\", \"tests\": [{\"input\": \"new int[]{1, 2, 3, 4}, 3\", \"expected\": \"2\"}, {\"input\": \"new int[]{1, 2, 3, 4}, 5\", \"expected\": \"-1\"}]},\n",
    "  {\"id\": \"java_011_contains_duplicate\", \"prompt\": \"Write a Java method containsDuplicate that returns true if any value appears at least twice in the array.\", \"signature\": \"public static boolean containsDuplicate(int[] nums)\", \"tests\": [{\"input\": \"new int[]{1, 2, 3, 1}\", \"expected\": \"true\"}, {\"input\": \"new int[]{1, 2, 3, 4}\", \"expected\": \"false\"}]},\n",
    "  {\"id\": \"java_012_max_subarray_sum\", \"prompt\": \"Write a Java method maxSubArraySum that returns the largest sum of a contiguous subarray.\", \"signature\": \"public static int maxSubArraySum(int[] nums)\", \"tests\": [{\"input\": \"new int[]{-2,1,-3,4,-1,2,1,-5,4}\", \"expected\": \"6\"}, {\"input\": \"new int[]{1}\", \"expected\": \"1\"}]},\n",
    "  {\"id\": \"java_013_two_sum\", \"prompt\": \"Write a Java method hasTwoSum that returns true if there exist two distinct indices i and j such that nums[i] + nums[j] == target.\", \"signature\": \"public static boolean hasTwoSum(int[] nums, int target)\", \"tests\": [{\"input\": \"new int[]{2, 7, 11, 15}, 9\", \"expected\": \"true\"}, {\"input\": \"new int[]{1, 2, 3}, 10\", \"expected\": \"false\"}]},\n",
    "  {\"id\": \"java_014_is_anagram\", \"prompt\": \"Write a Java method isAnagram that returns true if two given strings are anagrams of each other.\", \"signature\": \"public static boolean isAnagram(String s, String t)\", \"tests\": [{\"input\": \"\\\"anagram\\\", \\\"nagaram\\\"\", \"expected\": \"true\"}, {\"input\": \"\\\"rat\\\", \\\"car\\\"\", \"expected\": \"false\"}]},\n",
    "  {\"id\": \"java_015_remove_whitespace\", \"prompt\": \"Write a Java method removeWhitespace that returns a new string with all whitespace removed.\", \"signature\": \"public static String removeWhitespace(String s)\", \"tests\": [{\"input\": \"\\\"a b c\\\"\", \"expected\": \"\\\"abc\\\"\"}, {\"input\": \"\\\"   hello   world   \\\"\", \"expected\": \"\\\"helloworld\\\"\"}]},\n",
    "  {\"id\": \"java_016_power\", \"prompt\": \"Write a Java method power that returns x raised to the power n (x^n).\", \"signature\": \"public static long power(int x, int n)\", \"tests\": [{\"input\": \"2, 3\", \"expected\": \"8\"}, {\"input\": \"5, 2\", \"expected\": \"25\"}]},\n",
    "  {\"id\": \"java_017_is_sorted\", \"prompt\": \"Write a Java method isSortedAscending that returns true if the array is sorted in ascending order.\", \"signature\": \"public static boolean isSortedAscending(int[] arr)\", \"tests\": [{\"input\": \"new int[]{1, 2, 3, 4}\", \"expected\": \"true\"}, {\"input\": \"new int[]{3, 2, 1}\", \"expected\": \"false\"}]},\n",
    "  {\"id\": \"java_018_second_largest\", \"prompt\": \"Write a Java method secondLargest that returns the second largest distinct number in the array.\", \"signature\": \"public static int secondLargest(int[] arr)\", \"tests\": [{\"input\": \"new int[]{1, 2, 3}\", \"expected\": \"2\"}, {\"input\": \"new int[]{5, 1, 5, 2}\", \"expected\": \"2\"}]},\n",
    "  {\"id\": \"java_019_is_rotation\", \"prompt\": \"Write a Java method isRotation that returns true if string b is a rotation of string a.\", \"signature\": \"public static boolean isRotation(String a, String b)\", \"tests\": [{\"input\": \"\\\"abcde\\\", \\\"cdeab\\\"\", \"expected\": \"true\"}, {\"input\": \"\\\"abcde\\\", \\\"abced\\\"\", \"expected\": \"false\"}]},\n",
    "  {\"id\": \"java_020_valid_parentheses\", \"prompt\": \"Write a Java method isValidParentheses that returns true if the input string containing brackets is valid.\", \"signature\": \"public static boolean isValidParentheses(String s)\", \"tests\": [{\"input\": \"\\\"()\\\"\", \"expected\": \"true\"}, {\"input\": \"\\\"([)]\\\"\", \"expected\": \"false\"}]}\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(benchmark)} test problems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Models\n",
    "\n",
    "**IMPORTANT**: Update the `PRUNED_MODEL_PATH` to point to your pruned model folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model_path = r\"../QwenCoder3B-Prunned\"\n",
    "\n",
    "original_model_path = \"Qwen/Qwen2.5-Coder-3B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading ORIGINAL model from HuggingFace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Fetching 2 files: 100%|██████████| 2/2 [02:53<00:00, 86.81s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 19.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Original model loaded on CPU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load original model\n",
    "print(\" Loading ORIGINAL model from HuggingFace...\")\n",
    "original_tokenizer = AutoTokenizer.from_pretrained(original_model_path, trust_remote_code=True)\n",
    "original_model = AutoModelForCausalLM.from_pretrained(\n",
    "    original_model_path,\n",
    "    torch_dtype=torch.float32,  # Use float32 for CPU\n",
    "    low_cpu_mem_usage=True,      # Optimize CPU memory usage\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"eager\"  # Explicitly use eager attention to avoid version check\n",
    ")\n",
    "print(f\"✓ Original model loaded on CPU\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading PRUNED model...\n"
     ]
    },
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must use alphanumeric chars, '-', '_' or '.'. The name cannot start or end with '-' or '.' and the maximum length is 96: '..\\QwenCoder3B-Prunned'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHFValidationError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/prune_llm/lib/python3.11/site-packages/transformers/utils/hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/prune_llm/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:106\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrepo_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfrom_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mto_id\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arg_name == \u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/prune_llm/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:160\u001b[39m, in \u001b[36mvalidate_repo_id\u001b[39m\u001b[34m(repo_id)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX.match(repo_id):\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must use alphanumeric chars, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m The name cannot start or end with \u001b[39m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and the maximum length is 96:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m--\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[31mHFValidationError\u001b[39m: Repo id must use alphanumeric chars, '-', '_' or '.'. The name cannot start or end with '-' or '.' and the maximum length is 96: '..\\QwenCoder3B-Prunned'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mHFValidationError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load pruned model\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m Loading PRUNED model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m pruned_tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpruned_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m pruned_model = AutoModelForCausalLM.from_pretrained(\n\u001b[32m     10\u001b[39m     pruned_model_path,\n\u001b[32m     11\u001b[39m     torch_dtype=torch.float32,  \u001b[38;5;66;03m# Use float32 for CPU\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     attn_implementation=\u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Explicitly use eager attention to avoid version check\u001b[39;00m\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Pruned model loaded on CPU\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/prune_llm/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:1089\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1086\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n\u001b[32m   1088\u001b[39m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m tokenizer_config = \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[32m   1091\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = tokenizer_config[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/prune_llm/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:921\u001b[39m, in \u001b[36mget_tokenizer_config\u001b[39m\u001b[34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[39m\n\u001b[32m    918\u001b[39m     token = use_auth_token\n\u001b[32m    920\u001b[39m commit_hash = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    938\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/prune_llm/lib/python3.11/site-packages/transformers/utils/hub.py:322\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    265\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    266\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    267\u001b[39m     **kwargs,\n\u001b[32m    268\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    269\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    271\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/prune_llm/lib/python3.11/site-packages/transformers/utils/hub.py:531\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    525\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPermissionError at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m when downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    526\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCheck cache directory permissions. Common causes: 1) another user is downloading the same model (please wait); \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    527\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m2) a previous download was canceled and the lock file needs manual removal.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    528\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    530\u001b[39m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m resolved_files = \u001b[43m[\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_get_cache_file_to_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfull_filenames\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved_files\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/prune_llm/lib/python3.11/site-packages/transformers/utils/hub.py:532\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    525\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPermissionError at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m when downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    526\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCheck cache directory permissions. Common causes: 1) another user is downloading the same model (please wait); \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    527\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m2) a previous download was canceled and the lock file needs manual removal.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    528\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    530\u001b[39m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[32m    531\u001b[39m resolved_files = [\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[43m_get_cache_file_to_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[32m    534\u001b[39m ]\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved_files\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/prune_llm/lib/python3.11/site-packages/transformers/utils/hub.py:143\u001b[39m, in \u001b[36m_get_cache_file_to_return\u001b[39m\u001b[34m(path_or_repo_id, full_filename, cache_dir, revision, repo_type)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_cache_file_to_return\u001b[39m(\n\u001b[32m    136\u001b[39m     path_or_repo_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    137\u001b[39m     full_filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    141\u001b[39m ):\n\u001b[32m    142\u001b[39m     \u001b[38;5;66;03m# We try to see if we have a cached version (not up to date):\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     resolved_file = \u001b[43mtry_to_load_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resolved_file != _CACHED_NO_EXIST:\n\u001b[32m    147\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/prune_llm/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:106\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m arg_name, arg_value \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mzip\u001b[39m(signature.parameters, args),  \u001b[38;5;66;03m# Args values\u001b[39;00m\n\u001b[32m    103\u001b[39m     kwargs.items(),  \u001b[38;5;66;03m# Kwargs values\u001b[39;00m\n\u001b[32m    104\u001b[39m ):\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrepo_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfrom_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mto_id\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m         \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m arg_name == \u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    109\u001b[39m         has_token = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/prune_llm/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:160\u001b[39m, in \u001b[36mvalidate_repo_id\u001b[39m\u001b[34m(repo_id)\u001b[39m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    155\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must be in the form \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrepo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnamespace/repo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Use `repo_type` argument if needed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m     )\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX.match(repo_id):\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must use alphanumeric chars, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m The name cannot start or end with \u001b[39m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and the maximum length is 96:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m--\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot have -- or .. in repo_id: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mHFValidationError\u001b[39m: Repo id must use alphanumeric chars, '-', '_' or '.'. The name cannot start or end with '-' or '.' and the maximum length is 96: '..\\QwenCoder3B-Prunned'."
     ]
    }
   ],
   "source": [
    "# Load pruned model\n",
    "print(\" Loading PRUNED model...\")\n",
    "pruned_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pruned_model_path,\n",
    "    trust_remote_code=True,\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "pruned_model = AutoModelForCausalLM.from_pretrained(\n",
    "    pruned_model_path,\n",
    "    torch_dtype=torch.float32,  # Use float32 for CPU\n",
    "    low_cpu_mem_usage=True,      # Optimize CPU memory usage\n",
    "    trust_remote_code=True,\n",
    "    local_files_only=True,\n",
    "    attn_implementation=\"eager\"  # Explicitly use eager attention to avoid version check\n",
    ")\n",
    "\n",
    "print(\"✓ Pruned model loaded on CPU\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper Functions\n",
    "These functions help us generate code and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions ready!\n"
     ]
    }
   ],
   "source": [
    "def generate_code(model, tokenizer, task):\n",
    "    \"\"\"\n",
    "    Generate Java code for a given task using a model.\n",
    "    Returns: (generated_code, time_taken_in_seconds)\n",
    "    \"\"\"\n",
    "    signature = task[\"signature\"]\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Write ONLY the Java method for this task:\n",
    "{task['prompt']}\n",
    "\n",
    "Signature: {signature}\n",
    "\n",
    "Write the complete method:\"\"\"\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Generate and measure time\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,\n",
    "            temperature=0.2,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Decode only the new tokens\n",
    "    gen_ids = output_ids[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    code = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
    "    \n",
    "    # Clean up the output\n",
    "    code = code.replace(\"```java\", \"\").replace(\"```\", \"\").strip()\n",
    "    \n",
    "    # Extract just the method\n",
    "    if \"public static\" in code:\n",
    "        code = code[code.index(\"public static\"):]\n",
    "        if \"}\" in code:\n",
    "            code = code[:code.rfind(\"}\")+1]\n",
    "    \n",
    "    return code, elapsed_time\n",
    "\n",
    "\n",
    "def test_code(task, method_code):\n",
    "    \"\"\"\n",
    "    Test if the generated code passes all test cases.\n",
    "    Returns: True if all tests pass, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse signature to get return type and method name\n",
    "        sig_match = re.search(r'public\\s+static\\s+(\\S+)\\s+([A-Za-z_][A-Za-z0-9_]*)\\s*\\(', task[\"signature\"])\n",
    "        if not sig_match:\n",
    "            return False\n",
    "        \n",
    "        return_type, method_name = sig_match.group(1), sig_match.group(2)\n",
    "        \n",
    "        # Build test code\n",
    "        test_calls = []\n",
    "        for i, test in enumerate(task[\"tests\"], 1):\n",
    "            inp, expected = test[\"input\"], test[\"expected\"]\n",
    "            \n",
    "            if return_type == \"String\":\n",
    "                condition = f\"!{method_name}({inp}).equals({expected})\"\n",
    "            else:\n",
    "                condition = f\"{method_name}({inp}) != {expected}\"\n",
    "            \n",
    "            test_calls.append(f\"if ({condition}) throw new Exception(\\\"Test {i} failed\\\");\")\n",
    "        \n",
    "        # Create full Java file\n",
    "        java_code = f\"\"\"\n",
    "public class Main {{\n",
    "    {method_code}\n",
    "    \n",
    "    public static void main(String[] args) {{\n",
    "        try {{\n",
    "            {chr(10).join('            ' + tc for tc in test_calls)}\n",
    "            System.out.println(\"OK\");\n",
    "        }} catch (Exception e) {{\n",
    "            System.out.println(\"FAIL\");\n",
    "        }}\n",
    "    }}\n",
    "}}\n",
    "\"\"\"\n",
    "        \n",
    "        # Write to file\n",
    "        os.makedirs(\"temp\", exist_ok=True)\n",
    "        with open(\"temp/Main.java\", \"w\") as f:\n",
    "            f.write(java_code)\n",
    "        \n",
    "        # Compile\n",
    "        compile_result = subprocess.run([\"javac\", \"temp/Main.java\"], capture_output=True, text=True)\n",
    "        if compile_result.returncode != 0:\n",
    "            return False\n",
    "        \n",
    "        # Run\n",
    "        run_result = subprocess.run([\"java\", \"-cp\", \"temp\", \"Main\"], capture_output=True, text=True, timeout=5)\n",
    "        return run_result.stdout.strip() == \"OK\"\n",
    "        \n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "print(\"Helper functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Comparison\n",
    "Test both models on all problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comparison...\n",
      "\n",
      "============================================================\n",
      "\n",
      "[1/20] Testing: java_001_is_prime\n",
      "  → Original model... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namnd\\AppData\\Local\\miniconda3\\envs\\prune_llm\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\namnd\\AppData\\Local\\miniconda3\\envs\\prune_llm\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\namnd\\AppData\\Local\\miniconda3\\envs\\prune_llm\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:623: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ PASS (297.53s)\n",
      "  → Pruned model... "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pruned_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Test pruned model\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  → Pruned model...\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m pruned_code, pruned_time = generate_code(\u001b[43mpruned_model\u001b[49m, pruned_tokenizer, task)\n\u001b[32m     21\u001b[39m pruned_pass = test_code(task, pruned_code)\n\u001b[32m     22\u001b[39m pruned_results.append({\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: task[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpassed\u001b[39m\u001b[33m\"\u001b[39m: pruned_pass, \u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m: pruned_time})\n",
      "\u001b[31mNameError\u001b[39m: name 'pruned_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Store results\n",
    "original_results = []\n",
    "pruned_results = []\n",
    "\n",
    "print(\"Starting comparison...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, task in enumerate(benchmark, 1):\n",
    "    print(f\"\\n[{i}/{len(benchmark)}] Testing: {task['id']}\")\n",
    "    \n",
    "    # Test original model\n",
    "    print(\"  → Original model...\", end=\" \")\n",
    "    orig_code, orig_time = generate_code(original_model, original_tokenizer, task)\n",
    "    orig_pass = test_code(task, orig_code)\n",
    "    original_results.append({\"id\": task[\"id\"], \"passed\": orig_pass, \"time\": orig_time})\n",
    "    print(f\"{'✓ PASS' if orig_pass else '✗ FAIL'} ({orig_time:.2f}s)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Comparison complete!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Calculate statistics\noriginal_passed = sum(1 for r in original_results if r[\"passed\"])\npruned_passed = sum(1 for r in pruned_results if r[\"passed\"])\n\noriginal_avg_time = sum(r[\"time\"] for r in original_results) / len(original_results)\npruned_avg_time = sum(r[\"time\"] for r in pruned_results) / len(pruned_results)\n\ntotal_tests = len(benchmark)\n\n# Display results\nprint(\"\\n\" + \"=\"*60)\nprint(\"                    FINAL RESULTS\")\nprint(\"=\"*60)\nprint()\nprint(f\"Total Problems: {total_tests}\")\nprint()\nprint(\"ACCURACY (How many problems solved correctly):\")\nprint(f\"  Original Model: {original_passed}/{total_tests} = {original_passed/total_tests*100:.1f}%\")\nprint(f\"  Pruned Model:   {pruned_passed}/{total_tests} = {pruned_passed/total_tests*100:.1f}%\")\nprint(f\"  Difference:     {pruned_passed - original_passed} problems ({(pruned_passed - original_passed)/total_tests*100:+.1f}%)\")\nprint()\nprint(\"SPEED (Average time per problem):\")\nprint(f\"  Original Model: {original_avg_time:.3f} seconds\")\nprint(f\"  Pruned Model:   {pruned_avg_time:.3f} seconds\")\nprint(f\"  Speedup:        {original_avg_time/pruned_avg_time:.2f}x {'faster' if pruned_avg_time < original_avg_time else 'slower'}\")\nprint()\nprint(\"=\"*60)\n\n# Show which problems each model got wrong\noriginal_failed = [r[\"id\"] for r in original_results if not r[\"passed\"]]\npruned_failed = [r[\"id\"] for r in pruned_results if not r[\"passed\"]]\n\nif original_failed:\n    print(f\"\\nOriginal model failed on: {', '.join(original_failed)}\")\nif pruned_failed:\n    print(f\"Pruned model failed on: {', '.join(pruned_failed)}\")\n\n# Save generated code to files\nos.makedirs(\"../outputs\", exist_ok=True)\n\n# Check if generated code was captured\nif original_results and \"generated_code\" in original_results[0]:\n    # Save original model solutions\n    with open(\"../outputs/original_model_solutions.txt\", \"w\", encoding=\"utf-8\") as f:\n        f.write(\"=\"*80 + \"\\n\")\n        f.write(\"ORIGINAL MODEL GENERATED SOLUTIONS\\n\")\n        f.write(\"=\"*80 + \"\\n\\n\")\n        for result in original_results:\n            f.write(f\"\\n{'='*80}\\n\")\n            f.write(f\"Problem: {result['id']}\\n\")\n            f.write(f\"Status: {'PASS ✓' if result['passed'] else 'FAIL ✗'}\\n\")\n            f.write(f\"Time: {result['time']:.2f}s\\n\")\n            f.write(f\"{'='*80}\\n\\n\")\n            f.write(result['generated_code'])\n            f.write(\"\\n\\n\")\n    print(\"\\n✓ Original model solutions saved to: outputs/original_model_solutions.txt\")\n    \n    # Save pruned model solutions\n    with open(\"../outputs/pruned_model_solutions.txt\", \"w\", encoding=\"utf-8\") as f:\n        f.write(\"=\"*80 + \"\\n\")\n        f.write(\"PRUNED MODEL GENERATED SOLUTIONS\\n\")\n        f.write(\"=\"*80 + \"\\n\\n\")\n        for result in pruned_results:\n            f.write(f\"\\n{'='*80}\\n\")\n            f.write(f\"Problem: {result['id']}\\n\")\n            f.write(f\"Status: {'PASS ✓' if result['passed'] else 'FAIL ✗'}\\n\")\n            f.write(f\"Time: {result['time']:.2f}s\\n\")\n            f.write(f\"{'='*80}\\n\\n\")\n            f.write(result['generated_code'])\n            f.write(\"\\n\\n\")\n    print(\"✓ Pruned model solutions saved to: outputs/pruned_model_solutions.txt\")\nelse:\n    print(\"\\n⚠ Generated code not available in current results.\")\n    print(\"To capture generated code, modify cell 12 to add 'generated_code' to results:\")\n    print(\"  original_results.append({'id': ..., 'passed': ..., 'time': ..., 'generated_code': orig_code})\")\n    print(\"  pruned_results.append({'id': ..., 'passed': ..., 'time': ..., 'generated_code': pruned_code})\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 6.5 Save Generated Code\nRe-generate and save the code solutions from both models",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(\"Generating code from both models and saving to files...\\n\")\n\n# Create output directory\nos.makedirs(\"../outputs\", exist_ok=True)\n\n# Open files for writing\noriginal_file = open(\"../outputs/original_model_solutions.txt\", \"w\", encoding=\"utf-8\")\npruned_file = open(\"../outputs/pruned_model_solutions.txt\", \"w\", encoding=\"utf-8\")\n\n# Write headers\noriginal_file.write(\"=\"*80 + \"\\n\")\noriginal_file.write(\"ORIGINAL MODEL GENERATED SOLUTIONS\\n\")\noriginal_file.write(\"=\"*80 + \"\\n\\n\")\n\npruned_file.write(\"=\"*80 + \"\\n\")\npruned_file.write(\"PRUNED MODEL GENERATED SOLUTIONS\\n\")\npruned_file.write(\"=\"*80 + \"\\n\\n\")\n\n# Generate and save code for each problem\nfor i, task in enumerate(benchmark, 1):\n    print(f\"[{i}/{len(benchmark)}] Generating for: {task['id']}\")\n    \n    # Generate from original model\n    print(\"  → Original model...\", end=\" \")\n    orig_code, orig_time = generate_code(original_model, original_tokenizer, task)\n    orig_pass = test_code(task, orig_code)\n    print(f\"{'✓' if orig_pass else '✗'}\")\n    \n    # Write to original file\n    original_file.write(f\"\\n{'='*80}\\n\")\n    original_file.write(f\"Problem: {task['id']}\\n\")\n    original_file.write(f\"Prompt: {task['prompt']}\\n\")\n    original_file.write(f\"Status: {'PASS ✓' if orig_pass else 'FAIL ✗'}\\n\")\n    original_file.write(f\"Time: {orig_time:.2f}s\\n\")\n    original_file.write(f\"{'='*80}\\n\\n\")\n    original_file.write(orig_code)\n    original_file.write(\"\\n\\n\")\n    \n    # Generate from pruned model\n    print(\"  → Pruned model...\", end=\" \")\n    pruned_code, pruned_time = generate_code(pruned_model, pruned_tokenizer, task)\n    pruned_pass = test_code(task, pruned_code)\n    print(f\"{'✓' if pruned_pass else '✗'}\")\n    \n    # Write to pruned file\n    pruned_file.write(f\"\\n{'='*80}\\n\")\n    pruned_file.write(f\"Problem: {task['id']}\\n\")\n    pruned_file.write(f\"Prompt: {task['prompt']}\\n\")\n    pruned_file.write(f\"Status: {'PASS ✓' if pruned_pass else 'FAIL ✗'}\\n\")\n    pruned_file.write(f\"Time: {pruned_time:.2f}s\\n\")\n    pruned_file.write(f\"{'='*80}\\n\\n\")\n    pruned_file.write(pruned_code)\n    pruned_file.write(\"\\n\\n\")\n\n# Close files\noriginal_file.close()\npruned_file.close()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"✓ Original model solutions saved to: outputs/original_model_solutions.txt\")\nprint(\"✓ Pruned model solutions saved to: outputs/pruned_model_solutions.txt\")\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Interactive Prompting\nTest both models with custom prompts",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed results to a JSON file\n",
    "results_data = {\n",
    "    \"summary\": {\n",
    "        \"total_tests\": total_tests,\n",
    "        \"original_accuracy\": f\"{original_passed/total_tests*100:.1f}%\",\n",
    "        \"pruned_accuracy\": f\"{pruned_passed/total_tests*100:.1f}%\",\n",
    "        \"original_avg_time\": f\"{original_avg_time:.3f}s\",\n",
    "        \"pruned_avg_time\": f\"{pruned_avg_time:.3f}s\",\n",
    "        \"speedup\": f\"{original_avg_time/pruned_avg_time:.2f}x\"\n",
    "    },\n",
    "    \"original_results\": original_results,\n",
    "    \"pruned_results\": pruned_results\n",
    "}\n",
    "\n",
    "os.makedirs(\"../outputs\", exist_ok=True)\n",
    "with open(\"../outputs/comparison_results.json\", \"w\") as f:\n",
    "    json.dump(results_data, f, indent=2)\n",
    "\n",
    "print(\"Results saved to: outputs/comparison_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prune_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}